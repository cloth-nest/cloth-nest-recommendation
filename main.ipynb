{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 7s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 2048)             0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D\n",
    "import tensorflow as tf\n",
    "\n",
    "############################ Defining Model##############################################\n",
    "model=ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "model.trainable=False\n",
    "model=tf.keras.Sequential([model,GlobalMaxPool2D()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pickle/images.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\phamm\\Downloads\\cloth-nest\\cloth-nest-recommendation\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/Downloads/cloth-nest/cloth-nest-recommendation/main.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m normal_result\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/Downloads/cloth-nest/cloth-nest-recommendation/main.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m images\u001b[39m=\u001b[39m[os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(imagePath,files) \u001b[39mfor\u001b[39;00m files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(imagePath)]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/phamm/Downloads/cloth-nest/cloth-nest-recommendation/main.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(images,\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mpickle/images.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/Downloads/cloth-nest/cloth-nest-recommendation/main.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m feature_list\u001b[39m=\u001b[39m[]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/phamm/Downloads/cloth-nest/cloth-nest-recommendation/main.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m tqdm(images):\n",
      "File \u001b[1;32mc:\\Users\\phamm\\.conda\\envs\\cloth-nest-recommendation\\lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pickle/images.pkl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from numpy.linalg import norm\n",
    "import tqdm\n",
    "\n",
    "############### One time Code: need to extract features of 44k images, U can run this  ######\n",
    "\n",
    "rootDir = \"data\"\n",
    "imagePath = os.path.join(rootDir, \"myntradataset\", \"images\")\n",
    "\n",
    "\n",
    "def image_preprocess(path,model):\n",
    "    img=image.load_img(path, target_size=(224,224))\n",
    "    img_arr=image.img_to_array(img)\n",
    "    ex_img_arr=  np.expand_dims(img_arr,axis=0)\n",
    "    pre_pr_img=preprocess_input(ex_img_arr)\n",
    "    result=model.predict(pre_pr_img).flatten()\n",
    "    normal_result=result/norm(result)\n",
    "    return normal_result\n",
    "\n",
    "images=[os.path.join(imagePath,files) for files in os.listdir(imagePath)]\n",
    "\n",
    "with open('pickle/images.pkl','wb') as file:\n",
    "    pickle.dump(images,file)\n",
    "    \n",
    "feature_list=[]\n",
    "for file in tqdm(images):\n",
    "    feature_list.append(image_preprocess(file, model))\n",
    "pickle.dump(feature_list,open('pickle/features.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################Loading stored Features and images##################################\n",
    "file_img=pickle.load(open('pickle\\images.pkl','rb'))\n",
    "feature_list=(pickle.load(open('pickle\\features.pkl','rb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Images to Local for Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlist as st\n",
    "\n",
    "st.title('Fashion Recommender system')## title of the webpage\n",
    "###################### Method to Save Uploaded Image into local############################\n",
    "def save_img(upload_img):\n",
    "    try:\n",
    "        with open(os.path.join('uploads',upload_img.name),'wb') as f:\n",
    "            f.write(upload_img.getbuffer())\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "########### To display upload button onto screen######################\n",
    "upload_img=st.file_uploader(\"Choose an image\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "######################## Method to Extract features of new query image#######################\n",
    "def feature_extraction(path,model):\n",
    "    img=image.load_img(path, target_size=(224,224))# Load image in size of 224,224,3\n",
    "    img_arr=image.img_to_array(img)# storing into array\n",
    "    ex_img_arr=np.expand_dims(img_arr,axis=0)## Expanding the dimension of image\n",
    "    pre_pr_img=preprocess_input(ex_img_arr)## preprocessing the image\n",
    "    result=model.predict(pre_pr_img).flatten()### to make 1d vector\n",
    "    normal_result=result/norm(result)## Normalize the result using norm func from linalg(numpy)\n",
    "    return normal_result\n",
    "\n",
    "def prod_recom(features, feature_list):\n",
    "    neb=NearestNeighbors(n_neighbors=10,algorithm='brute',metric='euclidean') #using brute force algo here as data is not too big\n",
    "    neb.fit(feature_list)## fit with feature list\n",
    "    dist, ind=neb.kneighbors([features])# return distance and index but we use index to find out nearest images from stored features vector \n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import steamlist as st\n",
    "import time\n",
    "\n",
    "### Condition to check if image got uploaded then call save_img method to save and preprocess image followed by extract features and recommendation\n",
    "if upload_img is not None:\n",
    "    if save_img(upload_img):\n",
    "        st.image(Image.open(upload_img))     \n",
    "        st.header(\"file uploaded successfully\")\n",
    "        features=feature_extraction(os.path.join(\"uploads\",upload_img.name),model)\n",
    "        progress_text = \"Hold on! Result will shown below.\"\n",
    "        my_bar = st.progress(0, text=progress_text)\n",
    "        for percent_complete in range(100):\n",
    "            time.sleep(0.02)\n",
    "            my_bar.progress(percent_complete + 1, text=progress_text) ## to add progress bar untill feature got extracted\n",
    "        ind=prod_recom(features, feature_list)# calling recom. func to get 10 recommendation\n",
    "        ### to create 10 section of images into the screen\n",
    "        col1,col2,col3,col4,col5,col6,col7,col8,col9,col10=st.columns(10)\n",
    "        \n",
    "        ##for each section image shown by below code\n",
    "        with col1:\n",
    "            st.image(Image.open(file_img[ind[0][0]]))\n",
    "        with col2:\n",
    "            st.image(Image.open(file_img[ind[0][1]]))\n",
    "        with col3:\n",
    "            st.image(Image.open(file_img[ind[0][2]]))\n",
    "        with col4:\n",
    "            st.image(Image.open(file_img[ind[0][3]]))\n",
    "        with col5:\n",
    "            st.image(Image.open(file_img[ind[0][4]]))\n",
    "        with col6:\n",
    "            st.image(Image.open(file_img[ind[0][5]]))\n",
    "        with col7:\n",
    "            st.image(Image.open(file_img[ind[0][6]]))\n",
    "        with col8:\n",
    "            st.image(Image.open(file_img[ind[0][7]]))\n",
    "        with col9:\n",
    "            st.image(Image.open(file_img[ind[0][8]]))\n",
    "        with col10:\n",
    "            st.image(Image.open(file_img[ind[0][9]]))\n",
    "        # st.text(\"Using Spotify ANNoy\")\n",
    "        # df = pd.DataFrame({'img_id':file_img, 'img_repr': feature_list})\n",
    "        # f=len(df['img_repr'][0])\n",
    "        # ai=AnnoyIndex(f,'angular')        \n",
    "        # for i in tqdm(range(len(feature_list))):\n",
    "        #     v=feature_list[i]\n",
    "        #     ai.add_item(i,v)\n",
    "        # ai.build(10) # no of binary tress want to build more number of tree more accuracy \n",
    "        # neigh=(ai.get_nns_by_item(0,5))\n",
    "        # with col1:\n",
    "        #         st.image(Image.open(file_img[neigh[0]]))\n",
    "        # with col2:\n",
    "        #                 st.image(Image.open(file_img[neigh[1]]))\n",
    "        # with col3:\n",
    "        #                 st.image(Image.open(file_img[neigh[2]]))\n",
    "        # with col4:\n",
    "        #                 st.image(Image.open(file_img[neigh[3]]))\n",
    "\n",
    "        # for i in range(len(neigh)):\n",
    "        #     with st.columns(i):\n",
    "        #         st.image(Image.open(file_img[neigh[i]]))\n",
    "    else:\n",
    "        st.header(\"Some error occured\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-nest-recommendation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
